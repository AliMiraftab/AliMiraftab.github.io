---
layout: post
title: "Topic Modeling"
date: 2024-06-23
---

# In Progress
# Topic Modeling 

## LDA
LDA represents documents as a mixture of topics. Similarly, a topic is a mixture of words. If a word has high probability of being in a topic, all the documents having w will be more strongly associated with t as well.
### Caveats
- LDA works off the premise that documents with the same topic will have a lot of words in common.
- LDA is a bag of words model meaning that it only considers individual tokens and not their relationships in a sentence.

# Refrences
[A Beginnerâ€™s Guide to Latent Dirichlet Allocation(LDA)](https://medium.com/@corymaklin/latent-dirichlet-allocation-dfcea0b1fddc)
[Latent Dirichlet Allocation](https://medium.com/@corymaklin/latent-dirichlet-allocation-dfcea0b1fddc)
